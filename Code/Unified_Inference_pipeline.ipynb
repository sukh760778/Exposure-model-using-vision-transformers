{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad73abe-39ac-4451-bdf7-a2c1321773d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building image classification using vision transformer\n",
    "## Article: Developing Building Exposure Models Using Computer Vision and Deep Learning\n",
    "#\n",
    "# Authors: Sukh Sagar Shukla, Amit Bhatiya, Dhanya J, Saman Ghaffarian, Roberto Gentile\n",
    "#\n",
    "# Description:\n",
    "# This script provides a unified pipeline for the image classification task using Google Street View Panorama images.\n",
    "# This script processes a folder of images to:\n",
    "# 1. Detect and crop buildings using TensorFlow Hub's Faster R-CNN model\n",
    "# 2. Remove duplicate cropped images using feature similarity\n",
    "# 3. Classify unique buildings using a trained BEiT model\n",
    "# Please refer to the article for further details.\n",
    "# The present model can classify images into 24 building classes ['AD_H1', 'AD_H2', 'MR_H1 flat roof', 'MR_H1 gable roof', \n",
    "                   # 'MR_H2 flat roof', 'MR_H2 gable roof', 'MR_H3', 'Metal_H1', \n",
    "                   # 'Non_Building', 'RCC_H1 flat roof', 'RCC_H1 gable roof', \n",
    "                   # 'RCC_H2 flat roof', 'RCC_H2 gable roof', 'RCC_H3 flat roof', \n",
    "                   # 'RCC_H3 gable roof', 'RCC_H4 flat roof', 'RCC_H4 gaqble roof', \n",
    "                   # 'RCC_H5', 'RCC_H6', 'RCC_OS_H1', 'RCC_OS_H2', 'RCC_OS_H3', \n",
    "                   # 'RCC_OS_H4', 'Timber']\n",
    "# output_folder/\n",
    "# ├── cropped/              # Detected buildings (intermediate)\n",
    "# ├── original/             # Unique building images\n",
    "# ├── duplicate/            # Duplicate building images\n",
    "# └── classification_results.xlsx  # Classification results\n",
    "\n",
    "# Necessary libraries \n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from transformers import BeitForImageClassification, BeitConfig\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: BUILDING DETECTION AND CROPPING\n",
    "# ============================================================================\n",
    "def crop_and_save(original_image, box, save_path, expand_factor=0.1, min_dim=200):\n",
    "    \"\"\"Crops and saves an image based on a bounding box.\"\"\"\n",
    "    img_height, img_width, _ = original_image.shape\n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    box_width = xmax - xmin\n",
    "    box_height = ymax - ymin\n",
    "    expand_w = box_width * expand_factor\n",
    "    expand_h = box_height * expand_factor\n",
    "    xmin_expanded = max(0, xmin - expand_w)\n",
    "    ymin_expanded = max(0, ymin - expand_h)\n",
    "    xmax_expanded = min(1, xmax + expand_w)\n",
    "    ymax_expanded = min(1, ymax + expand_h)\n",
    "    xmin_pixel = int(xmin_expanded * img_width)\n",
    "    ymin_pixel = int(ymin_expanded * img_height)\n",
    "    xmax_pixel = int(xmax_expanded * img_width)\n",
    "    ymax_pixel = int(ymax_expanded * img_height)\n",
    "    cropped_image = original_image[ymin_pixel:ymax_pixel, xmin_pixel:xmax_pixel]\n",
    "    \n",
    "    cropped_height, cropped_width, _ = cropped_image.shape\n",
    "    if cropped_width < min_dim or cropped_height < min_dim:\n",
    "        return\n",
    "    cropped_image = (cropped_image * 255).astype(np.uint8)\n",
    "    try:\n",
    "        cropped_image_pil = Image.fromarray(cropped_image)\n",
    "        cropped_image_pil.save(save_path, format=\"JPEG\", quality=180)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving image: {str(e)}\")\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculates the Intersection over Union (IoU) of two bounding boxes.\"\"\"\n",
    "    y1_1, x1_1, y2_1, x2_1 = box1\n",
    "    y1_2, x1_2, y2_2, x2_2 = box2\n",
    "    intersection_y1 = max(y1_1, y1_2)\n",
    "    intersection_x1 = max(x1_1, x1_2)\n",
    "    intersection_y2 = min(y2_1, y2_2)\n",
    "    intersection_x2 = min(x2_1, x2_2)\n",
    "    intersection_area = max(0, intersection_x2 - intersection_x1) * max(0, intersection_y2 - intersection_y1)\n",
    "    \n",
    "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "    \n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    \n",
    "    return intersection_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def detect_and_crop_buildings(image_path, output_dir, detector=None):\n",
    "    \"\"\"Detects and crops buildings from an image.\"\"\"\n",
    "    print(f\"Processing: {os.path.basename(image_path)}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load detector if not provided (for reuse across images)\n",
    "    if detector is None:\n",
    "        module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "        detector = hub.load(module_handle).signatures['default']\n",
    "    \n",
    "    TARGET_CLASSES = ['House', 'Building', 'Skyscraper', 'Tower']\n",
    "    \n",
    "    original_image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    image = np.array(Image.open(image_path)) / 255.0\n",
    "    \n",
    "    converted_img = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]\n",
    "    result = detector(converted_img)\n",
    "    \n",
    "    final_detections = []\n",
    "    \n",
    "    for i in range(len(result['detection_boxes'])):\n",
    "        class_name = result['detection_class_entities'][i].numpy().decode('utf-8')\n",
    "        if class_name in TARGET_CLASSES and result['detection_scores'][i] >= 0.25:\n",
    "            current_box = result['detection_boxes'][i].numpy()\n",
    "            current_score = result['detection_scores'][i].numpy()\n",
    "            \n",
    "            is_duplicate = False\n",
    "            for existing_detection in final_detections:\n",
    "                if calculate_iou(current_box, existing_detection['box']) > 0.5:\n",
    "                    is_duplicate = True\n",
    "                    break\n",
    "            \n",
    "            if not is_duplicate:\n",
    "                final_detections.append({\n",
    "                    'class': class_name,\n",
    "                    'box': current_box,\n",
    "                    'score': current_score,\n",
    "                })\n",
    "    \n",
    "    for i, detection in enumerate(final_detections):\n",
    "        save_path = os.path.join(output_dir, f'{original_image_name}_{i+1}.jpg')\n",
    "        crop_and_save(image, detection['box'], save_path)\n",
    "    \n",
    "    print(f\"  - Found {len(final_detections)} buildings\")\n",
    "    return detector\n",
    "\n",
    "def process_folder_for_buildings(input_folder, output_dir):\n",
    "    \"\"\"Process all images in a folder for building detection.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"STEP 1: Detecting and cropping buildings from all images\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get list of valid image files\n",
    "    valid_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "    image_files = [f for f in os.listdir(input_folder) \n",
    "                   if f.lower().endswith(valid_extensions)]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {input_folder}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images to process\\n\")\n",
    "    \n",
    "    # Load detector once for all images\n",
    "    print(\"Loading detection model...\")\n",
    "    module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "    detector = hub.load(module_handle).signatures['default']\n",
    "    print(\"Model loaded successfully\\n\")\n",
    "    \n",
    "    # Process each image\n",
    "    for idx, img_file in enumerate(image_files, 1):\n",
    "        img_path = os.path.join(input_folder, img_file)\n",
    "        print(f\"[{idx}/{len(image_files)}] \", end=\"\")\n",
    "        try:\n",
    "            detect_and_crop_buildings(img_path, output_dir, detector)\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing {img_file}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nBuilding detection complete. Cropped images saved to: {output_dir}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: DUPLICATE IMAGE DETECTION AND REMOVAL\n",
    "# ============================================================================\n",
    "def load_cnn_model():\n",
    "    \"\"\"Loads the EfficientNetB7 model.\"\"\"\n",
    "    return EfficientNetB7(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "\n",
    "def extract_features(img_path, model):\n",
    "    \"\"\"Extracts features from an image using the CNN model.\"\"\"\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (600, 600))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    features = model.predict(img)\n",
    "    return features.flatten()\n",
    "\n",
    "def find_and_separate_duplicates(input_dir, original_dir, duplicate_dir):\n",
    "    \"\"\"Finds and separates duplicate images.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"STEP 2: Finding and separating duplicate images\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    os.makedirs(original_dir, exist_ok=True)\n",
    "    os.makedirs(duplicate_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Loading feature extraction model...\")\n",
    "    model = load_cnn_model()\n",
    "    \n",
    "    features = []\n",
    "    image_paths = []\n",
    "    \n",
    "    print(\"Extracting features from images...\")\n",
    "    for img_name in os.listdir(input_dir):\n",
    "        img_path = os.path.join(input_dir, img_name)\n",
    "        if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            try:\n",
    "                feat = extract_features(img_path, model)\n",
    "                features.append(feat)\n",
    "                image_paths.append(img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_name}: {e}\")\n",
    "    \n",
    "    if not features:\n",
    "        print(\"No valid images found for duplicate detection\")\n",
    "        return\n",
    "    \n",
    "    features = np.array(features)\n",
    "   # Cluster images based on feature similarity\n",
    "    # eps=0.26: maximum distance between samples to be considered neighbours \n",
    "    # min_samples=2: minimum cluster size (2 means at least one duplicate)\n",
    "    # These parametrs are optimised for a sample set of 200 images\n",
    "    print(f\"Clustering {len(features)} images...\")\n",
    "    dbscan = DBSCAN(eps=0.26, min_samples=2, metric=\"cosine\")\n",
    "    cluster_labels = dbscan.fit_predict(features)\n",
    "    \n",
    "    cluster_dict = {}\n",
    "    for idx, cluster_id in enumerate(cluster_labels):\n",
    "        if cluster_id not in cluster_dict:\n",
    "            cluster_dict[cluster_id] = []\n",
    "        cluster_dict[cluster_id].append(image_paths[idx])\n",
    "    \n",
    "    duplicate_count = 0\n",
    "    for cluster_id, img_list in cluster_dict.items():\n",
    "        if cluster_id == -1:\n",
    "            for img in img_list:\n",
    "                shutil.move(img, os.path.join(original_dir, os.path.basename(img)))\n",
    "        else:\n",
    "            shutil.move(img_list[0], os.path.join(original_dir, os.path.basename(img_list[0])))\n",
    "            for img in img_list[1:]:\n",
    "                shutil.move(img, os.path.join(duplicate_dir, os.path.basename(img)))\n",
    "                duplicate_count += 1\n",
    "    \n",
    "    original_count = len(os.listdir(original_dir))\n",
    "    print(f\"\\nDuplicate separation complete:\")\n",
    "    print(f\"  - Original images: {original_count}\")\n",
    "    print(f\"  - Duplicate images: {duplicate_count}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: IMAGE CLASSIFICATION\n",
    "# ============================================================================\n",
    "def load_classification_model(checkpoint_path, num_classes):\n",
    "    \"\"\"Loads the trained classification model.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    config = BeitConfig.from_pretrained(\n",
    "        \"microsoft/beit-base-patch16-224-pt22k-ft22k\",\n",
    "        num_labels=num_classes,\n",
    "        id2label={str(i): f\"CLASS_{i}\" for i in range(num_classes)},\n",
    "        label2id={f\"CLASS_{i}\": i for i in range(num_classes)}\n",
    "    )\n",
    "    model = BeitForImageClassification.from_pretrained(\n",
    "        \"microsoft/beit-base-patch16-224-pt22k-ft22k\",\n",
    "        config=config,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device)['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model, device\n",
    "\n",
    "def classify_image(model, device, image_path, class_names):\n",
    "    \"\"\"Classifies a single image.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        \n",
    "    return class_names[predicted.item()]\n",
    "\n",
    "def classify_and_save_results(image_dir, checkpoint_path, num_classes, class_names, output_excel_path):\n",
    "    \"\"\"Classifies images in a directory and saves the results to an Excel file.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"STEP 3: Classifying images and saving results\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"Loading classification model...\")\n",
    "    model, device = load_classification_model(checkpoint_path, num_classes)\n",
    "    print(f\"Using device: {device}\\n\")\n",
    "    \n",
    "    results = []\n",
    "    image_files = [f for f in os.listdir(image_dir) \n",
    "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    print(f\"Classifying {len(image_files)} images...\")\n",
    "    for idx, img_name in enumerate(image_files, 1):\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        try:\n",
    "            predicted_class = classify_image(model, device, img_path, class_names)\n",
    "            results.append({\"Image\": img_name, \"Classification\": predicted_class})\n",
    "            if idx % 10 == 0:\n",
    "                print(f\"  Processed {idx}/{len(image_files)} images\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error classifying {img_name}: {e}\")\n",
    "            \n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "    print(f\"\\nClassification complete. Results saved to: {output_excel_path}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function that runs the complete pipeline:\n",
    "    1. Detect and crop buildings from all images in input folder\n",
    "    2. Remove duplicate cropped images\n",
    "    3. Classify unique buildings and save results\n",
    "    \n",
    "    Configuration:\n",
    "        - Update INPUT_FOLDER with your input image directory\n",
    "        - Update BASE_OUTPUT_DIR with your desired output location\n",
    "        - Update CLASSIFICATION_MODEL_CHECKPOINT with your model path\n",
    "        - Update NUM_CLASSES and CLASS_NAMES to match your model\n",
    "    \"\"\"\n",
    "    # ========================================================================\n",
    "    # CONFIGURATION - UPDATE THESE PATHS ACCORDING TO YOUR DATA \n",
    "    # ========================================================================\n",
    "\n",
    "    INPUT_FOLDER = \"path to your panorama directory\"\n",
    "    BASE_OUTPUT_DIR = \"path to your base output directory\"\n",
    "    CROPPED_DIR = os.path.join(BASE_OUTPUT_DIR, \"cropped\")\n",
    "    ORIGINAL_DIR = os.path.join(BASE_OUTPUT_DIR, \"original\")\n",
    "    DUPLICATE_DIR = os.path.join(BASE_OUTPUT_DIR, \"duplicate\")\n",
    "    CLASSIFICATION_RESULTS_EXCEL = os.path.join(BASE_OUTPUT_DIR, \"classification_results.xlsx\")\n",
    "    \n",
    "  # ========================================================================\n",
    "    # CLASSIFICATION MODEL CONFIGURATION\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Path to your trained classification model checkpoint\n",
    "    CLASSIFICATION_MODEL_CHECKPOINT = \"path of the directory where best model is saved/best_model.pth\"\n",
    "    \n",
    "    # Number of classes the BEiT model of this study is trained on\n",
    "    NUM_CLASSES = 24\n",
    "    \n",
    "    # Class names corresponding present model's output labels\n",
    "    CLASS_NAMES = [\n",
    "        'AD_H1',                    # Adobe House with single storey\n",
    "        'AD_H2',                    # Adobe House having 2 storeys\n",
    "        'MR_H1 flat roof',          # Masonry House 1 storey - Flat Roof\n",
    "        'MR_H1 gable roof',         # Masonry House 1 storey - Gable Roof\n",
    "        'MR_H2 flat roof',          # Masonry House 2-storey - Flat Roof\n",
    "        'MR_H2 gable roof',         # Masonry House 2-storey - Gable Roof\n",
    "        'MR_H3',                    # Masonry House 3 storey\n",
    "        'Metal_H1',                 # Metal Structure with single storey\n",
    "        'Non_Building',             # Non-Building images\n",
    "        'RCC_H1 flat roof',         # RCC House 1 storey - Flat Roof\n",
    "        'RCC_H1 gable roof',        # RCC House 1 storey - Gable Roof\n",
    "        'RCC_H2 flat roof',         # RCC House 2-storey - Flat Roof\n",
    "        'RCC_H2 gable roof',        # RCC House 2-storey - Gable Roof\n",
    "        'RCC_H3 flat roof',         # RCC House 3 storey - Flat Roof\n",
    "        'RCC_H3 gable roof',        # RCC House 3 storey - Gable Roof\n",
    "        'RCC_H4 flat roof',         # RCC House 4 storey - Flat Roof\n",
    "        'RCC_H4 gaqble roof',       # RCC House 4 storey - Gable Roof\n",
    "        'RCC_H5',                   # RCC House 5 storey\n",
    "        'RCC_H6',                   # RCC House 6 storey\n",
    "        'RCC_OS_H1',                # RCC House 1 storey - presence of open storey\n",
    "        'RCC_OS_H2',                # RCC House 2 storey - presence of open storey\n",
    "        'RCC_OS_H3',                # RCC House 3 storey - presence of open storey\n",
    "        'RCC_OS_H4',                # RCC House 4 storey - presence of open storey\n",
    "        'Timber'                    # Timber Structure\n",
    "    ]\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PIPELINE EXECUTION\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Create base output directory\n",
    "    os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # Print pipeline header\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BATCH IMAGE PROCESSING PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Input folder: {INPUT_FOLDER}\")\n",
    "    print(f\"Output folder: {BASE_OUTPUT_DIR}\")\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "    \n",
    "    # Step 1: Detect and crop buildings from all images in folder\n",
    "    process_folder_for_buildings(INPUT_FOLDER, CROPPED_DIR)\n",
    "    \n",
    "    # Step 2: Find and separate duplicate cropped images\n",
    "    find_and_separate_duplicates(CROPPED_DIR, ORIGINAL_DIR, DUPLICATE_DIR)\n",
    "    \n",
    "    # Step 3: Classify unique buildings and save results to Excel\n",
    "    classify_and_save_results(\n",
    "        ORIGINAL_DIR, \n",
    "        CLASSIFICATION_MODEL_CHECKPOINT, \n",
    "        NUM_CLASSES, \n",
    "        CLASS_NAMES, \n",
    "        CLASSIFICATION_RESULTS_EXCEL\n",
    "    )\n",
    "    \n",
    "    # Print completion message\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
